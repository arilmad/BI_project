{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miner notebook\n",
    "\n",
    "Purpose: Extract rules from the data using the apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some sample transactions to get to know the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [\n",
    "    ['beer', 'diapers'],\n",
    "    ['diapers', 'milk'],\n",
    "    ['beer', 'nuts', 'diapers'],    \n",
    "    ['milk', 'nuts']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_confidence=0.8, min_support=0.5)\n",
    "l = list(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelationRecord(items=frozenset({'diapers', 'beer'}), support=0.5, ordered_statistics=[OrderedStatistic(items_base=frozenset({'beer'}), items_add=frozenset({'diapers'}), confidence=1.0, lift=1.3333333333333333)])]\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably need some pretty print for this.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_records(rec_list):\n",
    "    r = rec_list.copy()\n",
    "    for row in r:\n",
    "        print(f'Items:  {set(row.items)}')\n",
    "        print(f'Support: {row.support:.4f}')\n",
    "        print('BODY -> HEAD[Confidence, Lift]\\n')\n",
    "        for os in row.ordered_statistics:\n",
    "            print(f'\\t{set(os.items_base)}  ->  {set(os.items_add)}[{os.confidence:.2f}, {os.lift:.2f}]\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'diapers', 'beer'}\n",
      "Support: 0.5000\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'beer'}  ->  {'diapers'}[1.00, 1.33]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pprint_records(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>consumption_kvah</th>\n",
       "      <th>temperature</th>\n",
       "      <th>el_price</th>\n",
       "      <th>oil_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>26.330000</td>\n",
       "      <td>66.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.430000</td>\n",
       "      <td>66.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>66.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>66.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>66.730003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    loc_id  consumption_kvah  temperature   el_price  \\\n",
       "time                                                                   \n",
       "2018-01-01 00:00:00      0              27.0          5.5  26.330000   \n",
       "2018-01-01 01:00:00      0              27.5          5.0  26.430000   \n",
       "2018-01-01 02:00:00      0              27.0          4.8  26.100000   \n",
       "2018-01-01 03:00:00      0              23.0          4.9  24.700001   \n",
       "2018-01-01 04:00:00      0              23.0          3.7  24.740000   \n",
       "\n",
       "                     oil_price  \n",
       "time                            \n",
       "2018-01-01 00:00:00  66.730003  \n",
       "2018-01-01 01:00:00  66.730003  \n",
       "2018-01-01 02:00:00  66.730003  \n",
       "2018-01-01 03:00:00  66.730003  \n",
       "2018-01-01 04:00:00  66.730003  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_raw = pd.read_csv('cleansed_data//all_consumption_metadata.csv', parse_dates=True, index_col=0,\n",
    "                     dtype={'loc_id':'str', 'consumption_kvah':'float32', 'temperature':'float32',\n",
    "                           'el_price':'float32', 'oil_price':'float32'})\n",
    "all_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of 0: 18385\n",
      "Length of 1: 18385\n",
      "Length of 3: 18385\n",
      "Length of 4: 18385\n",
      "Length of 6: 18385\n",
      "Length of 10: 18385\n",
      "Length of 11: 18385\n",
      "Length of 12: 18385\n",
      "Length of 16: 18385\n",
      "Length of 17: 18385\n",
      "Length of 18: 18385\n",
      "Length of 19: 18385\n",
      "Length of 7: 18344\n",
      "Length of 8: 16111\n",
      "Length of 14: 15299\n",
      "Length of 2: 15134\n",
      "Length of 5: 14001\n",
      "Length of 15: 12493\n",
      "Length of 13: 6090\n",
      "Length of 9: 11783\n"
     ]
    }
   ],
   "source": [
    "loc_ids = all_df['loc_id'].unique()\n",
    "\n",
    "d = {}\n",
    "\n",
    "for loc in loc_ids: \n",
    "    d[loc] = all_df[all_df['loc_id']==loc]\n",
    "    print(f'Length of {loc}: {len(d[loc])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 is probably a nice sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = d['13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(20,5))\n",
    "ax.plot(sample['consumption_kvah'][:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be, might not be. Considering the distinct even peaks this timeseries is probably not representative of private householdings, but rather some commercial customer.\n",
    "\n",
    "It should do for prototyping anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The validity** of the apriori algortithm is heavily dependent on the categorization of numerical values. Probably have to try a few approaches\n",
    "\n",
    "#### **Test 1**: Bucket all numerical values in percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '13'\n",
    "sample = d[loc]\n",
    "sample = sample.drop(['loc_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentile_mask_dict(df, means=None, stds=None):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    cols = df_copy.columns\n",
    "    \n",
    "    # Use either a supplied means and stds list or extract from the given data\n",
    "    if means==None: means = [np.mean(df_copy[c]) for c in cols]\n",
    "    if stds==None: stds = [np.std(df_copy[c]) for c in cols]\n",
    "        \n",
    "    masks = {}\n",
    "    masks['m3std'] = [df_copy[c]<(m-3*s) for c, m, s in zip(cols, means, stds)]\n",
    "    masks['m2std'] = [(df_copy[c]<(m-2*s)) & ~m3std for c, m, s, m3std in zip(cols, means, stds, masks['m3std'])]\n",
    "    masks['m1std'] = [(df_copy[c]<(m-s)) & ~(m3std|m2std) for c, m, s, m3std, m2std in zip(cols, means, stds, masks['m3std'], masks['m2std'])]\n",
    "\n",
    "    masks['m0std'] = [(df_copy[c]<=(m+s)) & ~(m3std|m2std|m1std) for c, m, s, m3std, m2std, m1std \n",
    "                 in zip(cols, means, stds, masks['m3std'], masks['m2std'], masks['m1std'])]\n",
    "\n",
    "    masks['p3std'] = [df_copy[c]>(m+3*s) for c, m, s in zip(cols, means, stds)]\n",
    "    masks['p2std'] = [(df_copy[c]>(m+2*s)) & ~p3std for c, m, s, p3std in zip(cols, means, stds, masks['p3std'])]\n",
    "    masks['p1std'] = [(df_copy[c]>(m+s)) & ~(p3std|p2std) for c, m, s, p3std, p2std in zip(cols, means, stds, masks['p3std'], masks['p2std'])]\n",
    "    \n",
    "    return masks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transactions_array(d, n):\n",
    "    transactions = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < n:\n",
    "        row = []\n",
    "        for name, m in d.items():\n",
    "            for entry in m:\n",
    "                if entry[i]: row.append(name+'_'+entry.name)\n",
    "        transactions.append(row)\n",
    "        i += 1\n",
    "        \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = create_percentile_mask_dict(sample)\n",
    "n = len(masks['m0std'][0])\n",
    "    \n",
    "transactions = create_transactions_array(masks, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample is only 6000 rows, so we should be smart about choosing support threshold.\n",
    "\n",
    " * Too low threshold might find false rules. Some relationships might happen by chance in a few rows.\n",
    " * Finding rules for rare occurrences is not necessarily of value compared to strong everyday rules.\n",
    " * Too high threshold might overlook interesting relationships.\n",
    "\n",
    " \n",
    "One much-used example is demanding 50 occurrences over 10,000 rows. I.e. min_support=0.005.\n",
    "\n",
    "Given the size of our dataset, at 6,000 rows, we'll start out with min_support of 1%. This gives us rules with quite solid grounding.\n",
    "\n",
    "Playing with confidence and lift to filter out the strongest rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.7, min_lift=10)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our most solid rule with support threshold at 1%. When oil price $\\in (0.2,2.1)$  percentile, so is probably the el price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.6, min_lift=2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surprising remark**: When temperature $\\in (97.7, 99.8)$ percentile, the consumption is typically moderately high.\n",
    "\n",
    "This could say something about this particular customer, and it's likely that this rule won't hold water for the other locations in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run percentile mining on `Oilspot_prices` and `Elspot_prices`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have daily values on oilspot prices, and hourly on elspot, it's probably fair to resample the elspot prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oilspot = pd.read_csv('cleansed_data//Oilspot_prices.csv', index_col=0, parse_dates=True, dtype='float32')\n",
    "oilspot['day'] = oilspot.index.date\n",
    "oilspot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling to compare day by day since we only have daily oil prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elspot_raw = pd.read_csv('cleansed_data//Elspot_prices.csv', index_col=0, parse_dates=True, dtype='float32')\n",
    "\n",
    "elspot = elspot.resample(rule='D').mean()\n",
    "elspot['day'] = elspot.index.date\n",
    "elspot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_el = oilspot.merge(elspot, how='inner', left_on='day', right_on='day', suffixes=('_oil', '_el'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_el_days = oil_el['day']\n",
    "oil_el = oil_el.drop('day', axis=1)\n",
    "oil_el.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First out: Use the charateristics of the data before merge. For oil prices at least, we have one more year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.mean(df['price']) for df in [oilspot, elspot]]\n",
    "stds = [np.std(df['price']) for df in [oilspot, elspot]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_masks = create_percentile_mask_dict(oil_el, means=means, stds=stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we do have a timestamp available, so why not extract some rules from it as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_mask_dict(date_ts, weekday=False, month=False):\n",
    "    \n",
    "    df = date_ts.copy().to_frame()\n",
    "    \n",
    "    date_col = df.columns[0]\n",
    "    \n",
    "    masks = {}\n",
    "    \n",
    "    if weekday:\n",
    "        df['weekday'] = [d.weekday() for d in df[date_col]]\n",
    "        \n",
    "        weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "        for i, day in enumerate(weekdays):\n",
    "            masks[day] = [df['weekday']==i]\n",
    "            \n",
    "    if month:\n",
    "        df['month'] = [d.month for d in df[date_col]]\n",
    "        \n",
    "        months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "                  'August', 'September', 'October', 'November', 'December']\n",
    "        \n",
    "        for i, m in enumerate(months):\n",
    "            masks[m] = [df['month']==i]\n",
    "        \n",
    "    return masks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_masks = create_date_mask_dict(oil_el_days, weekday=True, month=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_masks = date_masks.copy()\n",
    "all_masks.update(perc_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(date_masks['Monday'][0])\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = create_transactions_array(all_masks, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again is time to be smart about the length of the data. It's quite short (800 rows), so demanding 5% support is probably not a bad idea. That is, at least 40 rows must contain our frequent itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.8, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few strong connections here. A lift above one means there is a definite value to the rule. What we seem to get from this is that typical oil prices typically imply typical el prices. But the buckets are defined to be largest at the typical values anyway. And the low lift implies that typical values are prevalent anyway.\n",
    "\n",
    "Might dare to lower support a bit. 2.5% support means 20 rows must contain the itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.8, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n*0.0266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! So, 22 rows seem to definitely imply that a very strong drop in oil prices drew el prices down as well!\n",
    "\n",
    "This is the strongest rule by far for this support. No other rule is even above lift 1.2.\n",
    "\n",
    "This is somewhat interesting given the fact that 98% of Norway's electricity production is renewable, but we're of course not detached from trade either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any difference if we use the stds and means from the merged data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_masks = create_percentile_mask_dict(oil_el)\n",
    "all_masks = date_masks.copy()\n",
    "all_masks.update(perc_masks)\n",
    "transactions = create_transactions_array(all_masks, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.8, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. We'll use the characteristics of the merged data from now on, to have a fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How 'bout weather and el prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv('cleansed_data//Weather.csv', index_col=[0,1], \n",
    "                dtype={'temperature':'float32', 'weather_station':'str'}, parse_dates=True)\n",
    "w.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make one complete temperature series using the median measurement in Agder for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = min(w.index.get_level_values(0))\n",
    "last_date = max(w.index.get_level_values(0))\n",
    "median_temps = pd.DataFrame(index=pd.date_range(start=first_date, end=last_date, freq='H'), columns=['temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_temps['temperature'] = [np.nanmedian(w.loc[idx]) for idx in median_temps.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_temps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_temps['day'] = median_temps.index.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_el = median_temps.merge(elspot_raw, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_el_days = temp_el['day']\n",
    "temp_el = temp_el.drop('day', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_el.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_masks = create_percentile_mask_dict(temp_el)\n",
    "date_masks = create_date_mask_dict(temp_el_days, weekday=True, month=True)\n",
    "\n",
    "all_masks = date_masks.copy()\n",
    "all_masks.update(perc_masks)\n",
    "\n",
    "n = len(perc_masks['m0std'][0])\n",
    "transactions = create_transactions_array(all_masks, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19,000 rows. Demanding first 0.005% support first, i.e. ~95 rows back our itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.8, min_lift=10)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some suspicious rules here. You're much more likely to be in August month if the temperatures are really high and the el prices are moderately high. Not that surprising. Also, if you happen to find yourself on a Saturday when prices are really low, you're much more likely than elsewhen to find out that the month is March and the temperature is moderate!\n",
    "\n",
    "Skipping weekdays and months and going down to 0.0025% support, i.e. 50 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = create_transactions_array(perc_masks, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.0025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.6, min_lift=1.4)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based of some ~60 rows found with both normal temperature and really low el prices, it seems that your best bet on temperature is that it is normal if prices are high. Furthermore, with the support of ~100 rows, it seems that temperatures during high prices are moderately low. \n",
    "\n",
    "This does not imply that low temperatures drive prices up, though. It can very well be the case that prices are mostly normal during colder times, but that when high prices occur, it's usually moderately cold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary thus far:\n",
    " * Strong indication that extremely low oil prices drive down el prices substantially.\n",
    " * In times of very high el prices, the weather is much more likely to be cold than elsewhen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumption and el prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using local weather and el prices at hourly frequency. All datasets should agree upon what's a low, medium and high el price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = min(all_raw.index)\n",
    "last_date = max(all_raw.index)\n",
    "\n",
    "el_price_subset = elspot_raw.loc[pd.date_range(start=first_date, end=last_date, freq='H')]\n",
    "\n",
    "el_subset_mean = np.mean(el_price_subset['price'])\n",
    "el_subset_std = np.std(el_price_subset['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy()\n",
    "        \n",
    "    df_copy = df_copy.drop(['loc_id', 'oil_price', 'temperature'], axis=1)\n",
    "    \n",
    "    means = [np.mean(df_copy['consumption_kvah']), el_subset_mean]\n",
    "    stds = [np.std(df_copy['consumption_kvah']), el_subset_std]\n",
    "    \n",
    "    perc_masks = create_percentile_mask_dict(df_copy, means=means, stds=stds)\n",
    "    \n",
    "    n = len(perc_masks['m0std'][0])\n",
    "    trans = create_transactions_array(perc_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 330,000 transactions! The apriori algorithm does not like very low thresholds, but we'll give this a shot.\n",
    "\n",
    "Let's start out moderately easy. 0.01% support means at least 3300 rows back us.\n",
    "\n",
    "Loc ids will probably not enter the equation before we lower the support threshold to find more specific rule. For now we'll keep them in a separated set of transactions to keep them off our results. Any general rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This high support threshold yields itemsets that are valid for (supported by) many rows. They might not yield extraordinary value since these occurrences are typical anyway. Thus the lift is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.05)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too general. All we have here is basically that what we usually see is the usual. \n",
    "\n",
    "Do we see any strong patterns for the different locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location 4 is the customer that the fact of there being moderate el prices increases the proability of having a moderate consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.5)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0010 * n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1% support means we need at least 330 rows to back the itemset. If you observe moderate prices and low consumption, you have a tremendous increase in probability that the location at which this happens is 14. This could also mean that location 14 is one of the few which has data in this period, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0.0005\n",
    "min_support * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.15)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.4)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At loc 15, when prices are very low, you're very likely to find that they have moderate consumption. Lift implies more so than elsewhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = np.mean(d['15']['consumption_kvah']), np.std(d['15']['consumption_kvah'])\n",
    "print(f'Normal consumption for 15 is between {m-s:.0f} and {m+s:.0f}')\n",
    "print(f'Low prices are between {el_subset_mean-2*el_subset_std:.0f} and {el_subset_mean-3*el_subset_std:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = d['15']['consumption_kvah'] > 6\n",
    "mask_2 = d['15']['consumption_kvah'] < 13\n",
    "mask_3 = mask_1 & mask_2\n",
    "\n",
    "mask_4 = el_price_subset['price'] < 21\n",
    "mask_5 = el_price_subset['price'] > 12\n",
    "mask_6 = mask_4 & mask_5\n",
    "\n",
    "mask_7 = mask_6 & mask_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = d['15'].index[0]\n",
    "end = d['15'].index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = pd.date_range(start=start, end=end, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].scatter(period, d['15'].loc[period]['consumption_kvah'], label='consumption')\n",
    "ax[0].scatter(period, pd.DataFrame(index=period, data=d['15'][mask_3])['consumption_kvah'], c='r', label='consumption within one std')\n",
    "ax[0].scatter(period, pd.DataFrame(index=period, data=d['15'][mask_7])['consumption_kvah'], c='g', label='consumption within one std when prices are between two and three stds below')\n",
    "ax[0].set_title('Consumption timeseries for loc id 15')\n",
    "\n",
    "ax[1].set_title('El prices')\n",
    "ax[1].scatter(period, el_price_subset.loc[period], label='prices')\n",
    "ax[1].scatter(period, pd.DataFrame(index=period, data=el_price_subset[mask_6])['price'], c='r', label='prices between two and three stds below')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This customer does indeed have some, though not very much, fluctuations in usage, and they are at normal levels when prices are low. However, they have also high consumption when prices are high.\n",
    "\n",
    "It could be useful to base the numbers on weekly or daily averages instead of overall averages and deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, s = np.mean(d['14']['consumption_kvah']), np.std(d['14']['consumption_kvah'])\n",
    "\n",
    "print(f'Minus 2 stds consumption for 14 is between {m-2*s:.0f} and {max(0,m-3*s):.0f}')\n",
    "print(f'Normal prices are between {el_subset_mean-el_subset_std:.0f} and {el_subset_mean+el_subset_std:.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = d['14']['consumption_kvah'] > 0\n",
    "mask_2 = d['14']['consumption_kvah'] < 4\n",
    "mask_3 = mask_1 & mask_2\n",
    "\n",
    "mask_4 = el_price_subset['price'] < 50\n",
    "mask_5 = el_price_subset['price'] > 31\n",
    "mask_6 = mask_4 & mask_5\n",
    "\n",
    "mask_7 = mask_6 & mask_3\n",
    "\n",
    "start = d['14'].index[0]\n",
    "end = d['14'].index[-1]\n",
    "\n",
    "period = pd.date_range(start=start, end=end, freq='H')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(20,10))\n",
    "ax[0].scatter(period, d['14'].loc[period]['consumption_kvah'], label='consumption')\n",
    "ax[0].scatter(period, pd.DataFrame(index=period, data=d['14'][mask_3])['consumption_kvah'], c='r', label='consumption between minus two and three stds')\n",
    "ax[0].scatter(period, pd.DataFrame(index=period, data=d['14'][mask_7])['consumption_kvah'], c='g', label='consumption between minus two and three stds when prices are normal')\n",
    "ax[0].set_title('Consumption timeseries for loc id 14')\n",
    "\n",
    "ax[1].set_title('El prices')\n",
    "ax[1].scatter(period, el_price_subset.loc[period], label='prices')\n",
    "ax[1].scatter(period, pd.DataFrame(index=period, data=el_price_subset[mask_6])['price'], c='r', label='normal prices')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that loc 14 has timeseries with missing values, or simply down time on their transformers. Nothing worth mentioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desperately need other categories!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare prices and consumption to last week's value at this time.\n",
    "\n",
    "How to do this: \n",
    " * Decide how fine resolution (n) you want for bucket size.\n",
    " * For each column, define n buckets between min and max value of that column.\n",
    " * Compare last week's bucket from this. (Last week I was in bucket 3, this week in bucket 5) -> The category is +2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 2.6, 4.7, 6.8, 8.9])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.5,11, (11-0.5)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shift_diff_mask_dict(df, n_buckets=10, shift=24*7, label='lw'):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    cols = df_copy.columns\n",
    "        \n",
    "    masks = {}\n",
    "    \n",
    "    shifted = df_copy.shift(shift)\n",
    "    shifted = shifted.dropna()\n",
    "    df_copy = df_copy.loc[shifted.index]\n",
    "        \n",
    "    diffs = pd.DataFrame(index=df_copy.index)\n",
    "    \n",
    "    for c in cols: \n",
    "        maxim = max(df_copy[c])\n",
    "        minim = min(df_copy[c])\n",
    "\n",
    "        arange = np.arange(minim, maxim, (maxim-minim)/n_buckets)\n",
    "\n",
    "        old = pd.DataFrame(index=shifted.index, columns=['bucket'], data=0)\n",
    "        new = pd.DataFrame(index=df_copy.index, columns=['bucket'], data=0)\n",
    "\n",
    "        for i, r in enumerate(arange):\n",
    "            old[shifted[c]>r] = i \n",
    "            new[df_copy[c]>r] = i\n",
    "            \n",
    "        diffs[c] = new['bucket'] - old['bucket'] \n",
    "     \n",
    "    \n",
    "    for n in range(-n_buckets+1, 0):\n",
    "        masks[f'm{(100/n_buckets * n*(-1)):.0f}'] = [diffs[c]==n for c in cols]\n",
    "    \n",
    "    for n in range(0, n_buckets):\n",
    "        masks[f'p{(100/n_buckets * n):.0f}'] = [diffs[c]==n for c in cols]\n",
    "        \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m25_temperature', 'p5_el_price'}\n",
      "Support: 0.0066\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m25_temperature'}  ->  {'p5_el_price'}[0.72, 3.34]\n",
      "\n",
      "\n",
      "Items:  {'m15_temperature', 'p5_el_price', 'p15_consumption_kvah'}\n",
      "Support: 0.0077\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m15_temperature', 'p15_consumption_kvah'}  ->  {'p5_el_price'}[0.79, 3.65]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.7, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.6775"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.0075\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m15_temperature', 'p5_el_price', 'p15_consumption_kvah'}\n",
      "Support: 0.0077\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m15_temperature', 'p15_consumption_kvah'}  ->  {'p5_el_price'}[0.79, 3.65]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.7, min_lift=1.15)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35000000000000003"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.2253\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.26]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=15, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35000000000000003"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'loc_0', 'p0_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_0', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.67, 1.87]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0118\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.68, 1.89]\n",
      "\n",
      "\n",
      "Items:  {'m7_temperature', 'p7_consumption_kvah', 'loc_10'}\n",
      "Support: 0.0056\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p7_consumption_kvah', 'loc_10'}  ->  {'m7_temperature'}[0.61, 2.62]\n",
      "\n",
      "\n",
      "Items:  {'loc_2', 'p7_consumption_kvah', 'm13_temperature'}\n",
      "Support: 0.0051\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_2', 'm13_temperature'}  ->  {'p7_consumption_kvah'}[0.67, 3.29]\n",
      "\n",
      "\n",
      "Items:  {'loc_4', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0061\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_4', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.67, 1.87]\n",
      "\n",
      "\n",
      "Items:  {'loc_4', 'p0_consumption_kvah', 'p7_temperature'}\n",
      "Support: 0.0056\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_4', 'p7_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.71]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_8'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_8'}  ->  {'p0_consumption_kvah'}[0.67, 1.87]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_9', 'p0_temperature'}\n",
      "Support: 0.0056\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_9', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.69, 1.92]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.15)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0169\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.73, 1.52]\n",
      "\n",
      "\n",
      "Items:  {'loc_17', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0153\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_17', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.81, 1.68]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_6'}\n",
      "Support: 0.0148\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_6'}  ->  {'p0_consumption_kvah'}[0.71, 1.46]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_8'}\n",
      "Support: 0.0118\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_8'}  ->  {'p0_consumption_kvah'}[0.74, 1.54]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_9', 'p0_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_9', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.73, 1.51]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.7, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.2253\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.26]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=2)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.685"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0119\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.66, 1.72]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_15', 'p0_temperature'}\n",
      "Support: 0.0057\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_15', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.65, 1.70]\n",
      "\n",
      "\n",
      "Items:  {'loc_17', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0088\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_17', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.63, 1.65]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_18', 'p0_temperature'}\n",
      "Support: 0.0103\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_18', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.65, 1.69]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_19', 'p0_temperature'}\n",
      "Support: 0.0114\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_consumption_kvah', 'loc_19'}  ->  {'p0_temperature'}[0.65, 2.28]\n",
      "\n",
      "\n",
      "Items:  {'loc_2', 'p0_consumption_kvah', 'p10_temperature'}\n",
      "Support: 0.0077\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_2', 'p10_temperature'}  ->  {'p0_consumption_kvah'}[0.60, 1.57]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_8'}\n",
      "Support: 0.0057\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_8'}  ->  {'p0_consumption_kvah'}[0.61, 1.60]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample per day, look at yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='D').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.74"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'loc_4', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0115\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_4', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.63]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'temperature'], axis=1).resample(rule='D').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=7)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price'], axis=1).resample(rule='M').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "min_support = 0.02\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m10_el_price', 'm40_consumption_kvah'}\n",
      "Support: 0.0311\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m40_consumption_kvah'}  ->  {'m10_el_price'}[1.00, 2.81]\n",
      "\n",
      "\n",
      "Items:  {'p40_temperature', 'm10_el_price'}\n",
      "Support: 0.0311\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p40_temperature'}  ->  {'m10_el_price'}[1.00, 2.81]\n",
      "\n",
      "\n",
      "Items:  {'m40_el_price', 'p10_temperature'}\n",
      "Support: 0.0400\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m40_el_price'}  ->  {'p10_temperature'}[0.95, 3.84]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.9, min_lift=2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m10_el_price', 'm40_consumption_kvah'}\n",
      "Support: 0.0311\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m40_consumption_kvah'}  ->  {'m10_el_price'}[1.00, 2.81]\n",
      "\n",
      "\n",
      "Items:  {'p40_temperature', 'm10_el_price'}\n",
      "Support: 0.0311\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p40_temperature'}  ->  {'m10_el_price'}[1.00, 2.81]\n",
      "\n",
      "\n",
      "Items:  {'m40_el_price', 'p10_temperature'}\n",
      "Support: 0.0400\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m40_el_price'}  ->  {'p10_temperature'}[0.95, 3.84]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.9, min_lift=2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'temperature'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.57"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_wo_loc_id)\n",
    "min_support = 0.01\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.95, min_lift=1.5)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1957"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(transactions_with_loc_id)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.57"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.01\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0169\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.73, 1.52]\n",
      "\n",
      "\n",
      "Items:  {'loc_17', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0153\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_17', 'p0_consumption_kvah'}  ->  {'p0_temperature'}[0.60, 1.62]\n",
      "\n",
      "\n",
      "\t{'loc_17', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.81, 1.68]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_8'}\n",
      "Support: 0.0118\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_8'}  ->  {'p0_consumption_kvah'}[0.74, 1.54]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_el_price', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0123\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_consumption_kvah', 'p0_el_price', 'loc_1'}  ->  {'p0_temperature'}[0.69, 1.85]\n",
      "\n",
      "\n",
      "\t{'p0_el_price', 'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.92, 1.91]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'p0_el_price', 'loc_6'}\n",
      "Support: 0.0102\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_consumption_kvah', 'p0_el_price', 'loc_6'}  ->  {'p0_temperature'}[0.71, 1.93]\n",
      "\n",
      "\n",
      "\t{'p0_el_price', 'p0_temperature', 'loc_6'}  ->  {'p0_consumption_kvah'}[0.74, 1.53]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.5)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.2253\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.26]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p20_el_price'}\n",
      "Support: 0.0215\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_el_price'}  ->  {'p0_consumption_kvah'}[0.63, 1.30]\n",
      "\n",
      "\n",
      "Items:  {'p0_el_price', 'p0_temperature'}\n",
      "Support: 0.2259\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_el_price'}[0.61, 1.24]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_el_price', 'p0_temperature'}\n",
      "Support: 0.1415\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_consumption_kvah', 'p0_temperature'}  ->  {'p0_el_price'}[0.63, 1.28]\n",
      "\n",
      "\n",
      "\t{'p0_el_price', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.63, 1.30]\n",
      "\n",
      "\n",
      "Items:  {'p0_el_price', 'p10_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0404\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p10_consumption_kvah', 'p0_temperature'}  ->  {'p0_el_price'}[0.61, 1.24]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.57"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.01\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.15)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'consumption_kvah', 'oil_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=20, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m10_temperature', 'p25_el_price'}\n",
      "Support: 0.0061\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p25_el_price'}  ->  {'m10_temperature'}[0.63, 4.43]\n",
      "\n",
      "\n",
      "Items:  {'m25_temperature', 'p5_el_price'}\n",
      "Support: 0.0066\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m25_temperature'}  ->  {'p5_el_price'}[0.72, 3.34]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.3)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'consumption_kvah', 'oil_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p30_el_price', 'm10_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p30_el_price'}  ->  {'m10_temperature'}[0.84, 3.23]\n",
      "\n",
      "\n",
      "Items:  {'m30_el_price', 'p0_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m30_el_price'}  ->  {'p0_temperature'}[0.89, 2.40]\n",
      "\n",
      "\n",
      "Items:  {'m30_temperature', 'p0_el_price'}\n",
      "Support: 0.0051\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m30_temperature'}  ->  {'p0_el_price'}[0.83, 1.69]\n",
      "\n",
      "\n",
      "Items:  {'p0_el_price', 'p0_temperature'}\n",
      "Support: 0.2259\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_el_price'}[0.61, 1.24]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'consumption_kvah', 'temperature'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m30_el_price', 'p10_oil_price'}\n",
      "Support: 0.0092\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m30_el_price'}  ->  {'p10_oil_price'}[1.00, 4.25]\n",
      "\n",
      "\n",
      "Items:  {'p0_el_price', 'p20_oil_price'}\n",
      "Support: 0.0169\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_oil_price'}  ->  {'p0_el_price'}[0.94, 1.92]\n",
      "\n",
      "\n",
      "Items:  {'p0_oil_price', 'p30_el_price'}\n",
      "Support: 0.0092\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p30_el_price'}  ->  {'p0_oil_price'}[0.95, 1.98]\n",
      "\n",
      "\n",
      "Items:  {'p20_el_price', 'p10_oil_price'}\n",
      "Support: 0.0240\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_el_price'}  ->  {'p10_oil_price'}[0.70, 2.98]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.2)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'el_price', 'temperature'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.785"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'temperature'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m30_el_price', 'p0_consumption_kvah'}\n",
      "Support: 0.0077\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m30_el_price'}  ->  {'p0_consumption_kvah'}[0.83, 1.73]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p20_el_price'}\n",
      "Support: 0.0215\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_el_price'}  ->  {'p0_consumption_kvah'}[0.63, 1.30]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'consumption_kvah'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=15, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m27_el_price', 'p0_temperature'}\n",
      "Support: 0.0056\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m27_el_price'}  ->  {'p0_temperature'}[0.61, 2.32]\n",
      "\n",
      "\n",
      "Items:  {'p7_el_price', 'm27_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m27_temperature'}  ->  {'p7_el_price'}[0.84, 5.20]\n",
      "\n",
      "\n",
      "Items:  {'m7_temperature', 'p27_el_price'}\n",
      "Support: 0.0061\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p27_el_price'}  ->  {'m7_temperature'}[0.63, 2.71]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_wo_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='W').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.2253\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.26]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'm10_temperature', 'loc_0'}\n",
      "Support: 0.0107\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m10_temperature', 'loc_0'}  ->  {'p0_consumption_kvah'}[0.62, 1.28]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_0', 'p0_temperature'}\n",
      "Support: 0.0123\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_0', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.67, 1.38]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_1', 'p0_temperature'}\n",
      "Support: 0.0169\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_1', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.73, 1.52]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_15', 'p0_temperature'}\n",
      "Support: 0.0077\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_15', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.65, 1.35]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'm10_temperature', 'loc_16'}\n",
      "Support: 0.0087\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m10_temperature', 'loc_16'}  ->  {'p0_consumption_kvah'}[0.68, 1.41]\n",
      "\n",
      "\n",
      "Items:  {'loc_17', 'p10_temperature', 'm10_consumption_kvah'}\n",
      "Support: 0.0066\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_17', 'p10_temperature'}  ->  {'m10_consumption_kvah'}[0.62, 3.21]\n",
      "\n",
      "\n",
      "Items:  {'loc_17', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0153\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_17', 'p0_consumption_kvah'}  ->  {'p0_temperature'}[0.60, 1.62]\n",
      "\n",
      "\n",
      "\t{'loc_17', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.81, 1.68]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_18', 'p0_temperature'}\n",
      "Support: 0.0148\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_18', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.67, 1.40]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'm10_temperature', 'loc_3'}\n",
      "Support: 0.0092\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m10_temperature', 'loc_3'}  ->  {'p0_consumption_kvah'}[0.60, 1.24]\n",
      "\n",
      "\n",
      "Items:  {'loc_4', 'p0_consumption_kvah', 'p0_temperature'}\n",
      "Support: 0.0133\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_4', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.68, 1.42]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_6'}\n",
      "Support: 0.0148\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_6'}  ->  {'p0_consumption_kvah'}[0.71, 1.46]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_7', 'p0_temperature'}\n",
      "Support: 0.0138\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_7', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.61, 1.27]\n",
      "\n",
      "\n",
      "Items:  {'p10_temperature', 'm10_consumption_kvah', 'loc_8'}\n",
      "Support: 0.0061\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m10_consumption_kvah', 'loc_8'}  ->  {'p10_temperature'}[0.63, 2.80]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'p0_temperature', 'loc_8'}\n",
      "Support: 0.0118\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p0_temperature', 'loc_8'}  ->  {'p0_consumption_kvah'}[0.74, 1.54]\n",
      "\n",
      "\n",
      "Items:  {'p0_consumption_kvah', 'loc_9', 'p0_temperature'}\n",
      "Support: 0.0082\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'loc_9', 'p0_temperature'}  ->  {'p0_consumption_kvah'}[0.73, 1.51]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price', 'el_price'], axis=1).resample(rule='M').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.05\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m20_temperature', 'p20_consumption_kvah'}\n",
      "Support: 0.0711\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_consumption_kvah'}  ->  {'m20_temperature'}[0.67, 3.06]\n",
      "\n",
      "\n",
      "Items:  {'m20_temperature', 'p30_consumption_kvah'}\n",
      "Support: 0.0533\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p30_consumption_kvah'}  ->  {'m20_temperature'}[0.65, 2.98]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_with_loc_id = []\n",
    "transactions_wo_loc_id = []\n",
    "\n",
    "for loc, df in d.items():\n",
    "    df_copy = df.copy().drop(['loc_id', 'oil_price'], axis=1).resample(rule='M').mean()\n",
    "    \n",
    "    diff_masks = create_shift_diff_mask_dict(df_copy, n_buckets=10, shift=1)\n",
    "    \n",
    "    n = len(diff_masks['p0'][0])\n",
    "    \n",
    "    trans = create_transactions_array(diff_masks, n)\n",
    "    \n",
    "    trans_loc = [t+[f'loc_{loc}'] for t in trans]\n",
    "\n",
    "    transactions_with_loc_id += trans_loc\n",
    "    transactions_wo_loc_id += trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m20_temperature', 'p20_consumption_kvah'}\n",
      "Support: 0.0711\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_consumption_kvah'}  ->  {'m20_temperature'}[0.67, 3.06]\n",
      "\n",
      "\n",
      "Items:  {'m20_temperature', 'p30_consumption_kvah'}\n",
      "Support: 0.0533\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p30_consumption_kvah'}  ->  {'m20_temperature'}[0.65, 2.98]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.02\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m25_el_price', 'p20_temperature'}\n",
      "Support: 0.0244\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p20_temperature'}  ->  {'m25_el_price'}[0.65, 14.56]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.6, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.01\n",
    "min_support*len(transactions_wo_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'m15_el_price', 'p40_temperature'}\n",
      "Support: 0.0178\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p40_temperature'}  ->  {'m15_el_price'}[0.89, 4.49]\n",
      "\n",
      "\n",
      "Items:  {'m15_el_price', 'm15_consumption_kvah', 'p5_temperature'}\n",
      "Support: 0.0111\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m15_el_price', 'm15_consumption_kvah'}  ->  {'p5_temperature'}[0.83, 8.93]\n",
      "\n",
      "\n",
      "Items:  {'m15_consumption_kvah', 'm20_el_price', 'p15_temperature'}\n",
      "Support: 0.0133\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m15_consumption_kvah', 'm20_el_price'}  ->  {'p15_temperature'}[0.86, 7.56]\n",
      "\n",
      "\n",
      "Items:  {'p10_temperature', 'm20_el_price', 'm20_consumption_kvah'}\n",
      "Support: 0.0111\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'m20_el_price', 'm20_consumption_kvah'}  ->  {'p10_temperature'}[0.83, 6.25]\n",
      "\n",
      "\n",
      "Items:  {'p10_el_price', 'p5_temperature', 'm5_consumption_kvah'}\n",
      "Support: 0.0111\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'p10_el_price', 'p5_temperature'}  ->  {'m5_consumption_kvah'}[1.00, 10.98]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions_with_loc_id, min_support=min_support, min_confidence=0.8, min_lift=1.1)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_support = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = pyfpgrowth.find_frequent_patterns(transactions, k_support)\n",
    "rules = pyfpgrowth.generate_association_rules(patterns, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.625"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "min_support*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items:  {'lw_p0_el_price', 'lw_p40_consumption_kvah', 'lw_m40_temperature'}\n",
      "Support: 0.0062\n",
      "BODY -> HEAD[Confidence, Lift]\n",
      "\n",
      "\t{'lw_p40_consumption_kvah', 'lw_m40_temperature'}  ->  {'lw_p0_el_price'}[0.71, 1.97]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = apriori(transactions, min_support=min_support, min_confidence=0.7, min_lift=1.5)\n",
    "pprint_records(list(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
